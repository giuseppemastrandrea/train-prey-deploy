{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8227539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import StructuredTool, tool\n",
    "from typing import List\n",
    "\n",
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a7ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are very powerful assistant, but don't know current events and reply in italian. You have access to the following tools:\\n\\n{tools}\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \"action\" field are: {tool_names}\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{{\\n  \"action\": $TOOL_NAME,\\n  \"action_input\": $INPUT\\n}}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\"\"\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5214b76c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a simple tool that uses the previously created model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9b1a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f9e85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain_openai import ChatOpenAI  # pip install langchain-openai\n",
    "\n",
    "# create a tool list with a model associated to it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d337915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddae3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93183337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the orchestrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a064aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the orchestrator\n",
    "# agent_executor.invoke({\"input\": \"Qual è la qualità di questo vino? 0.15929204 0.13013699 0.09       0.03424658 0.09015025 0.20895522 0.07773852 0.34424981 0.53543307 0.22155689 0.24615385\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1feea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the orchestrator\n",
    "# agent_executor.invoke({\"input\": \"Cosa c'è di bello a firenze?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83160523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
