{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Dataset sulla qualità dei vini\n",
    "\n",
    "This dataset is related to the red variants of the Portuguese wine \"Vinho Verde\". The dataset describes the quantity of various chemical substances present in the wine and allows to identify their effect on its quality. The dataset is available on Kaggle at the URL:\n",
    "\n",
    "https://www.kaggle.com/datasets/yasserh/wine-quality-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T13:42:45.639087300Z",
     "start_time": "2023-09-20T13:42:43.464170500Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install pandas matplotlib seaborn tensorflow scikit-learn --no-cache-dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library import\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-20T13:42:45.654088800Z",
     "start_time": "2023-09-20T13:42:45.640104400Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "df = pd.read_csv('data/WineQT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some information about the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# distributions of each feature\n",
    "# -> histograms\n",
    "\n",
    "for col in df.columns:\n",
    "    f, (ax1) = plt.subplots(1, 1, figsize=(6, 3) )\n",
    "    v_dist_1 = df[col].values\n",
    "    sns.histplot(v_dist_1, ax=ax1, color='orange', kde=True)\n",
    "\n",
    "    media = df[col].mean()\n",
    "    mediana = df[col].median()\n",
    "    moda = df[col].mode().values[0]\n",
    "\n",
    "    ax1.axvline(media, color='r', linestyle='--', label=\"Mean\")\n",
    "    ax1.axvline(mediana, color='g', linestyle='-', label=\"Median\")\n",
    "    ax1.axvline(moda, color='b', linestyle='-', label=\"Mode\")\n",
    "    ax1.legend()\n",
    "    plt.grid()\n",
    "    plt.title(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisi della distribuzione degli esempi disponibili\n",
    "# relativamente alla qualità di ognuno\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "df.quality.value_counts().plot(kind='pie')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analisi delle eventuali correlazioni\n",
    "# tramite una mappa di correlazione\n",
    "\n",
    "plt.figure(figsize=(6, 6), dpi=150)\n",
    "corr = df.corr()\n",
    "sns.heatmap(\n",
    "    corr, \n",
    "    xticklabels=corr.columns, \n",
    "    yticklabels=corr.columns, \n",
    "    cmap='viridis',\n",
    "    annot=True,\n",
    "    fmt=\".1f\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create the dataset\n",
    "\n",
    "Hints: \n",
    "- access just to the raw values\n",
    "- drop the columns you don't need (e.g. the target)\n",
    "- reserve a quota for the **test** dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do we need to scale the data?\n",
    "\n",
    "MinMax scaling is a way to adjust your numbers so that they fit into a specific range, usually between 0 and 1. Imagine you have a bunch of different-sized sticks, and you want to compare them more easily. By using MinMax scaling, you shrink or stretch each stick so that the smallest one becomes exactly 0 units long, and the longest one becomes 1 unit long. All the other sticks get a size in between, depending on how long they were to begin with. This method makes it simpler to compare all the sticks because they now have a common scale to measure against.\n",
    "\n",
    "\n",
    "<img src=\"assets/minmax.png\" width=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our First neural network!\n",
    "\n",
    "A neural network for a classification problem is like a smart helper that learns to sort things into different buckets. Imagine you have a big pile of fruits and you want to separate them into baskets labeled apples, bananas, and oranges. A neural network looks at each fruit, learns what each fruit type looks like by examining their features like color and shape, and then decides which basket to put them in. The more fruit it sees, the better it gets at sorting them correctly. So, a neural network helps us automatically sort or classify things into different groups based on what it has learned from examples.\n",
    "\n",
    "\n",
    "<img src=\"assets/neural_network.png\" width=600 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizzazione dell'addestramento\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.title('Mean squared error')\n",
    "plt.plot(log.history['loss'], label='train')\n",
    "plt.plot(log.history['val_loss'], label='test')\n",
    "plt.xlabel('epoche')\n",
    "plt.ylabel('errore')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.title('Mean absolute error')\n",
    "plt.plot(log.history['mean_absolute_error'], label='train')\n",
    "plt.plot(log.history['val_mean_absolute_error'], label='test')\n",
    "plt.xlabel('epoche')\n",
    "plt.ylabel('errore')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
